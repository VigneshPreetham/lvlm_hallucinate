# Thesis/ Capstone Project on LVLM Hallucinations
- I aim to reduce hallucinations with large vision language models
- An approach that I took is to use Recognize Anything Model (RAM) tags for an image and feed into the prompt
- RAM tags provide attributes and objects in the image
- It increased the test accuracy of the internVL-4B model when tested on the POPE benchmark by 20%

  
![dog_ram](https://github.com/user-attachments/assets/b8cd9364-2d16-4090-b836-b11ca8ab282c)
- The RAM tags are dog and tennis ball in this image

My Benchmark Data Collection
(the image was so big that it needed to be compressed below):
![SEQ_10_019_git-min](https://github.com/user-attachments/assets/f4d9ace1-c5f2-495d-b2cc-2c039c7fcdf4)

After Undergoing Automatic Annotation With Zoom:


![store_logos_ft-ezgif com-crop](https://github.com/user-attachments/assets/ac1d553b-ebd5-4f3f-ac28-7670e07fd632)
